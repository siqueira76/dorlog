/**
 * Servi√ßo de An√°lise NLP Client-Side para DorLog
 * 
 * Sistema isolado para processamento de linguagem natural
 * sem interferir nas funcionalidades existentes da aplica√ß√£o.
 */

import { pipeline, env } from '@xenova/transformers';
import type { 
  TextClassificationPipeline,
  SummarizationPipeline,
  ZeroShotClassificationPipeline
} from '@xenova/transformers';

// Detec√ß√£o de compatibilidade para GitHub Pages
interface EnvironmentConfig {
  name: string;
  allowRemoteModels: boolean;
  allowLocalModels: boolean;
  useBrowserCache: boolean;
  useWebGPU?: boolean;
}

// Detec√ß√£o de ambiente para otimiza√ß√£o
function detectEnvironment(): { isGitHubPages: boolean; isReplit: boolean; isLocal: boolean } {
  const hostname = typeof window !== 'undefined' ? window.location.hostname : '';
  return {
    isGitHubPages: hostname.includes('github.io'),
    isReplit: hostname.includes('replit.dev') || hostname.includes('replit.co'),
    isLocal: hostname === 'localhost' || hostname === '127.0.0.1'
  };
}

// Configura√ß√µes otimizadas por ambiente
function getEnvironmentConfig(envInfo: { isGitHubPages: boolean; isReplit: boolean; isLocal: boolean }): EnvironmentConfig {
  if (envInfo.isGitHubPages) {
    return {
      name: 'GitHub Pages',
      allowRemoteModels: true,  // Usar Hugging Face Hub (padr√£o)
      allowLocalModels: false,  // N√£o precisamos de modelos locais
      useBrowserCache: true,    // Cache otimizado para PWA
      useWebGPU: true          // Performance m√°xima
    };
  } else if (envInfo.isReplit) {
    return {
      name: 'Replit',
      allowRemoteModels: true,  // Usar Hugging Face Hub
      allowLocalModels: false,  // Evitar problemas de filesystem
      useBrowserCache: true,    // Habilitar cache para reduzir tempo de carregamento
      useWebGPU: false         // Compatibilidade primeiro
    };
  } else {
    return {
      name: 'Local/Outros',
      allowRemoteModels: true,
      allowLocalModels: false,
      useBrowserCache: true,
      useWebGPU: true
    };
  }
}

// Tipos para an√°lise NLP
export interface SentimentResult {
  label: 'POSITIVE' | 'NEGATIVE' | 'NEUTRAL';
  score: number;
  confidence: 'HIGH' | 'MEDIUM' | 'LOW';
}

export interface TextSummary {
  summary: string;
  keyPhrases: string[];
  length: number;
}

export interface EmotionalState {
  primary: string;
  intensity: number;
  confidence: number;
}

export interface MedicalEntity {
  entity: string;
  type: 'SYMPTOM' | 'MEDICATION' | 'BODY_PART' | 'TIME' | 'EMOTION';
  confidence: number;
}

export interface NLPAnalysisResult {
  sentiment: SentimentResult;
  summary?: TextSummary;
  emotions: EmotionalState[];
  entities: MedicalEntity[];
  urgencyLevel: number; // 0-10
  clinicalRelevance: number; // 0-10
}

// üöÄ OTIMIZA√á√ÉO FASE 1: Cache persistente e logging inteligente
interface ModelCache {
  [key: string]: {
    model: any;
    timestamp: number;
    version: string;
  };
}

// Sistema de logging otimizado para NLP
let NLP_VERBOSE_LOGGING = false;
const nlpLog = (message: string, ...args: any[]) => {
  if (NLP_VERBOSE_LOGGING) {
    console.log(message, ...args);
  }
};

// Singleton para garantir uma √∫nica inst√¢ncia de NLP compartilhada
class NLPSingleton {
  private static instance: NLPAnalysisService | null = null;
  private static initPromise: Promise<NLPAnalysisService> | null = null;

  static async getInstance(): Promise<NLPAnalysisService> {
    if (this.instance) return this.instance;
    
    if (this.initPromise) return this.initPromise;
    
    this.initPromise = this.createInstance();
    this.instance = await this.initPromise;
    this.initPromise = null;
    
    return this.instance;
  }

  private static async createInstance(): Promise<NLPAnalysisService> {
    const service = new NLPAnalysisService();
    await service.initialize();
    return service;
  }

  static resetInstance(): void {
    this.instance = null;
    this.initPromise = null;
  }
}

/**
 * Fun√ß√£o est√°tica para acessar a inst√¢ncia singleton de NLP
 */
export const getNLPInstance = async (): Promise<NLPAnalysisService> => {
  return NLPSingleton.getInstance();
};

/**
 * Fun√ß√£o para resetar a inst√¢ncia singleton (√∫til para testes)
 */
export const resetNLPInstance = (): void => {
  NLPSingleton.resetInstance();
};

/**
 * Classe principal para an√°lise NLP com cache persistente otimizado
 */
export class NLPAnalysisService {
  private sentimentPipeline: TextClassificationPipeline | null = null;
  private summaryPipeline: SummarizationPipeline | null = null;
  private classificationPipeline: ZeroShotClassificationPipeline | null = null;
  private isLoading = false;
  private initialized = false;
  private environmentInfo = detectEnvironment();
  private environmentConfig: EnvironmentConfig;
  private modelCache: ModelCache = {};
  private static readonly CACHE_EXPIRY_HOURS = 24;
  private static readonly CACHE_VERSION = '2.0';
  
  constructor() {
    this.environmentConfig = getEnvironmentConfig(this.environmentInfo);
    this.configureEnvironment();
  }
  
  /**
   * Configura ambiente baseado na detec√ß√£o (GitHub Pages, Replit, etc.)
   */
  private configureEnvironment(): void {
    const config = this.environmentConfig;
    
    console.log(`üåç Ambiente detectado: ${config.name}`);
    console.log('üéØ Configura√ß√£o otimizada:', {
      allowRemoteModels: config.allowRemoteModels,
      allowLocalModels: config.allowLocalModels,
      useBrowserCache: config.useBrowserCache
    });
    
    try {
      // Configurar transformers.js com configura√ß√µes corretas
      if (env && typeof env === 'object') {
        (env as any).allowRemoteModels = config.allowRemoteModels;
        (env as any).allowLocalModels = config.allowLocalModels;
        (env as any).useBrowserCache = config.useBrowserCache;
        
        // GitHub Pages espec√≠fico - n√£o configurar remoteHost (usar padr√£o HF Hub)
        if (this.environmentInfo.isGitHubPages) {
          console.log('üöÄ GitHub Pages: Usando Hugging Face Hub (padr√£o)');
          // N√£o configurar remoteHost - deixar padr√£o
        }
        
        console.log('‚úÖ Transformers.js configurado para', config.name);
      }
    } catch (error) {
      console.warn('‚ö†Ô∏è Configura√ß√£o de ambiente limitada, usando padr√µes');
    }
  }

  /**
   * Inicializa os modelos NLP (lazy loading) - vers√£o otimizada
   */
  async initialize(): Promise<void> {
    if (this.initialized || this.isLoading) return;
    
    this.isLoading = true;
    console.log('‚ö° Inicializando modelos NLP com CACHE OTIMIZADO...');

    try {
      // üöÄ OTIMIZA√á√ÉO: Tentar carregar do cache primeiro
      const cachedModel = this.getCachedModel('sentiment');
      if (cachedModel) {
        console.log('‚úÖ Modelo de sentimento carregado do CACHE');
        this.sentimentPipeline = cachedModel.model;
        this.initialized = true;
        this.isLoading = false;
        return;
      }

      // Carregar do Hugging Face Hub se n√£o estiver em cache
      nlpLog('üì• Carregando modelo de an√°lise de sentimento...');
      
      const initPromise = this.initializeSentimentModel();
      const timeoutPromise = new Promise<never>((_, reject) => 
        setTimeout(() => reject(new Error('Timeout na inicializa√ß√£o (30s)')), 30000)
      );
      
      await Promise.race([initPromise, timeoutPromise]);
      
      // üöÄ OTIMIZA√á√ÉO: Salvar no cache para uso futuro
      this.setCachedModel('sentiment', this.sentimentPipeline!);
      
      this.initialized = true;
      console.log('‚úÖ Modelo de sentimento inicializado e CACHEADO com sucesso');
      nlpLog('‚ÑπÔ∏è Outros modelos ser√£o carregados conforme necess√°rio');
      
    } catch (error) {
      console.error('‚ùå Erro ao inicializar modelo NLP:', error);
      console.error('üìù Detalhes do erro:', {
        message: error instanceof Error ? error.message : 'Erro desconhecido',
        stack: error instanceof Error ? error.stack : 'Stack n√£o dispon√≠vel'
      });
      
      // N√£o falhar completamente - usar fallback
      this.initialized = false;
      console.log('üîÑ Usando modo fallback baseado em regras');
    } finally {
      this.isLoading = false;
    }
  }

  /**
   * Inicializa apenas o modelo de sentimento
   */
  private async initializeSentimentModel(): Promise<void> {
    const modelName = 'Xenova/distilbert-base-uncased-finetuned-sst-2-english';
    this.sentimentPipeline = await this.loadModelWithOptimization(
      'text-classification',
      modelName
    ) as TextClassificationPipeline;
  }
  
  /**
   * Carrega modelo usando configura√ß√£o padr√£o (Hugging Face Hub)
   */
  private async loadModelWithOptimization(task: string, modelName: string, options?: any): Promise<any> {
    const config = this.environmentConfig;
    const timeout = config.name === 'GitHub Pages' ? 30000 : 20000; // Mais tempo para GitHub Pages
    
    console.log(`üì• Carregando modelo ${modelName} via Hugging Face Hub...`);
    
    try {
      // Usar configura√ß√£o padr√£o - n√£o sobrescrever URLs
      const modelPromise = pipeline(task as any, modelName, {
        ...options,
        // Para GitHub Pages, otimizar configura√ß√µes
        ...(this.environmentInfo.isGitHubPages && {
          device: config.useWebGPU ? 'webgpu' : 'cpu',
          dtype: 'fp32' // Compatibilidade m√°xima
        })
      });
      
      const timeoutPromise = new Promise<never>((_, reject) => 
        setTimeout(() => reject(new Error(`Timeout carregamento (${timeout/1000}s)`)), timeout)
      );
      
      const model = await Promise.race([modelPromise, timeoutPromise]);
      
      console.log(`‚úÖ Modelo ${modelName} carregado com sucesso`);
      return model;
      
    } catch (error) {
      console.error(`‚ùå Erro ao carregar modelo ${modelName}:`, error instanceof Error ? error.message : 'Erro desconhecido');
      throw error;
    }
  }

  /**
   * Inicializa modelo de sumariza√ß√£o sob demanda
   */
  private async initializeSummaryModel(): Promise<void> {
    if (this.summaryPipeline) return;
    
    try {
      console.log('üì• Carregando modelo de sumariza√ß√£o...');
      this.summaryPipeline = await this.loadModelWithOptimization(
        'summarization',
        'Xenova/t5-small'
      ) as SummarizationPipeline;
    } catch (error) {
      console.error('‚ùå Erro ao carregar modelo de sumariza√ß√£o:', error);
      throw error;
    }
  }

  /**
   * Inicializa modelo de classifica√ß√£o sob demanda
   */
  private async initializeClassificationModel(): Promise<void> {
    if (this.classificationPipeline) return;
    
    try {
      console.log('üì• Carregando modelo de classifica√ß√£o...');
      this.classificationPipeline = await this.loadModelWithOptimization(
        'zero-shot-classification',
        'Xenova/distilbert-base-uncased-mnli'
      ) as ZeroShotClassificationPipeline;
    } catch (error) {
      console.error('‚ùå Erro ao carregar modelo de classifica√ß√£o:', error);
      throw error;
    }
  }

  /**
   * Analisa sentimento de um texto
   */
  async analyzeSentiment(text: string): Promise<SentimentResult> {
    await this.initialize();
    
    // Se modelo de IA n√£o estiver dispon√≠vel, usar fallback
    if (!this.sentimentPipeline) {
      console.log('üîÑ Usando an√°lise de sentimento baseada em regras');
      return this.analyzeSentimentFallback(text);
    }

    try {
      const result = await this.sentimentPipeline!(text) as any;
      const output = Array.isArray(result) ? result[0] : result;
      
      return {
        label: output.label as 'POSITIVE' | 'NEGATIVE' | 'NEUTRAL',
        score: output.score || 0.5,
        confidence: (output.score || 0.5) > 0.8 ? 'HIGH' : (output.score || 0.5) > 0.6 ? 'MEDIUM' : 'LOW'
      };
    } catch (error) {
      console.error('‚ùå Erro na an√°lise de sentimento IA:', error);
      console.log('üîÑ Fallback para an√°lise baseada em regras');
      return this.analyzeSentimentFallback(text);
    }
  }

  /**
   * An√°lise de sentimento baseada em regras (fallback)
   */
  private analyzeSentimentFallback(text: string): SentimentResult {
    const textLower = text.toLowerCase();
    
    // Palavras positivas
    const positiveWords = ['bom', 'bem', 'melhor', 'otimo', '√≥timo', 'calmo', 'tranquilo', 'feliz', 'alegre', 'satisfeito', 'melhorou', 'aliviado'];
    const negativeWords = ['dor', 'mal', 'pior', 'terr√≠vel', 'insuport√°vel', 'preocupado', 'ansioso', 'triste', 'deprimido', 'crise', 'ruim', 'p√©ssimo'];
    
    let positiveScore = 0;
    let negativeScore = 0;
    
    positiveWords.forEach(word => {
      if (textLower.includes(word)) positiveScore++;
    });
    
    negativeWords.forEach(word => {
      if (textLower.includes(word)) negativeScore++;
    });
    
    let label: 'POSITIVE' | 'NEGATIVE' | 'NEUTRAL' = 'NEUTRAL';
    let score = 0.5;
    
    if (positiveScore > negativeScore) {
      label = 'POSITIVE';
      score = Math.min(0.9, 0.6 + (positiveScore * 0.1));
    } else if (negativeScore > positiveScore) {
      label = 'NEGATIVE';
      score = Math.min(0.9, 0.6 + (negativeScore * 0.1));
    }
    
    return {
      label,
      score,
      confidence: score > 0.8 ? 'HIGH' : score > 0.6 ? 'MEDIUM' : 'LOW'
    };
  }

  /**
   * Gera resumo de texto
   */
  async summarizeText(text: string, maxLength = 100): Promise<TextSummary> {
    // Verificar se o texto √© longo o suficiente para sumariza√ß√£o
    if (text.length < 50) {
      return {
        summary: text,
        keyPhrases: this.extractKeyPhrases(text),
        length: text.length
      };
    }

    // Tentar carregar modelo de sumariza√ß√£o se ainda n√£o foi carregado
    if (!this.summaryPipeline) {
      try {
        await this.initializeSummaryModel();
      } catch (error) {
        console.log('üîÑ Modelo de sumariza√ß√£o n√£o dispon√≠vel, usando fallback');
        return this.summarizeTextFallback(text, maxLength);
      }
    }

    try {
      const result = await this.summaryPipeline!(text, {
        max_length: maxLength,
        min_length: 20,
        do_sample: false
      }) as any;

      const summaryText = Array.isArray(result) ? result[0]?.summary_text || result[0]?.generated_text : result?.summary_text || result?.generated_text;

      return {
        summary: summaryText,
        keyPhrases: this.extractKeyPhrases(text),
        length: summaryText.length
      };
    } catch (error) {
      console.error('‚ùå Erro na sumariza√ß√£o IA:', error);
      return this.summarizeTextFallback(text, maxLength);
    }
  }

  /**
   * Sumariza√ß√£o baseada em regras (fallback)
   */
  private summarizeTextFallback(text: string, maxLength: number): TextSummary {
    // Pegar as primeiras frases mais relevantes
    const sentences = text.split(/[.!?]+/).filter(s => s.trim().length > 10);
    const medicalKeywords = ['dor', 'sintoma', 'medicamento', 'sono', 'humor', 'crise'];
    
    // Priorizar frases com palavras m√©dicas
    const relevantSentences = sentences.filter(sentence => 
      medicalKeywords.some(keyword => sentence.toLowerCase().includes(keyword))
    );
    
    const summaryText = relevantSentences.length > 0 
      ? relevantSentences.slice(0, 2).join('. ').substring(0, maxLength) + '...'
      : text.substring(0, maxLength) + '...';
    
    return {
      summary: summaryText,
      keyPhrases: this.extractKeyPhrases(text),
      length: summaryText.length
    };
  }

  /**
   * Classifica entidades m√©dicas no texto
   */
  async extractMedicalEntities(text: string): Promise<MedicalEntity[]> {
    // Tentar carregar modelo de classifica√ß√£o se ainda n√£o foi carregado
    if (!this.classificationPipeline) {
      try {
        await this.initializeClassificationModel();
      } catch (error) {
        console.log('üîÑ Modelo de classifica√ß√£o n√£o dispon√≠vel, usando fallback');
        return this.extractMedicalEntitiesFallback(text);
      }
    }

    const medicalLabels = [
      'sintoma m√©dico',
      'medicamento',
      'parte do corpo',
      'tempo de dura√ß√£o',
      'estado emocional',
      'dor',
      'tratamento'
    ];

    try {
      const result = await this.classificationPipeline!(text, medicalLabels) as any;
      const resultData = Array.isArray(result) ? result[0] : result;
      
      const entities: MedicalEntity[] = (resultData.labels || []).map((label: string, index: number) => {
        const score = (resultData.scores || [])[index] || 0.5;
        
        let entityType: MedicalEntity['type'] = 'EMOTION';
        if (label.includes('sintoma')) entityType = 'SYMPTOM';
        else if (label.includes('medicamento')) entityType = 'MEDICATION';
        else if (label.includes('corpo')) entityType = 'BODY_PART';
        else if (label.includes('tempo')) entityType = 'TIME';

        return {
          entity: label,
          type: entityType,
          confidence: score
        };
      }).filter((entity: MedicalEntity) => entity.confidence > 0.3);

      return entities;
    } catch (error) {
      console.error('‚ùå Erro na extra√ß√£o de entidades IA:', error);
      return this.extractMedicalEntitiesFallback(text);
    }
  }

  /**
   * Extra√ß√£o de entidades baseada em regras (fallback)
   */
  private extractMedicalEntitiesFallback(text: string): MedicalEntity[] {
    const textLower = text.toLowerCase();
    const entities: MedicalEntity[] = [];
    
    // Dicion√°rios de palavras por categoria
    const entityDict = {
      symptoms: ['dor', 'crise', 'ansiedade', 'depress√£o', 'cansa√ßo', 'mal-estar', 'n√°usea', 'tontura'],
      bodyParts: ['cabe√ßa', 'pesco√ßo', 'costas', 'bra√ßo', 'perna', 'est√¥mago', 'peito', 'olhos'],
      medications: ['rem√©dio', 'medicamento', 'dipirona', 'paracetamol', 'ibuprofeno', 'antidepressivo'],
      timeWords: ['minutos', 'horas', 'dias', 'semana', 'm√™s', 'hoje', 'ontem', 'sempre'],
      emotions: ['triste', 'feliz', 'preocupado', 'calmo', 'irritado', 'ansioso', 'deprimido']
    };
    
    // Detectar entidades por palavra-chave
    Object.entries(entityDict).forEach(([category, words]) => {
      words.forEach(word => {
        if (textLower.includes(word)) {
          let type: MedicalEntity['type'] = 'EMOTION';
          switch(category) {
            case 'symptoms': type = 'SYMPTOM'; break;
            case 'bodyParts': type = 'BODY_PART'; break;
            case 'medications': type = 'MEDICATION'; break;
            case 'timeWords': type = 'TIME'; break;
            case 'emotions': type = 'EMOTION'; break;
          }
          
          entities.push({
            entity: word,
            type,
            confidence: 0.7 // Confian√ßa m√©dia para detec√ß√£o por regras
          });
        }
      });
    });
    
    // Remover duplicatas
    const uniqueEntities = entities.filter((entity, index, self) => 
      index === self.findIndex(e => e.entity === entity.entity && e.type === entity.type)
    );
    
    return uniqueEntities.slice(0, 5); // Limitar a 5 entidades
  }

  /**
   * Detecta n√≠vel de urg√™ncia no texto
   */
  detectUrgencyLevel(text: string): number {
    const urgencyKeywords = {
      critical: ['insuport√°vel', 'desesperado', 'socorro', 'emerg√™ncia', 'n√£o aguento'],
      high: ['muito forte', 'muito ruim', 'piorou muito', 'preocupado', 'assustado'],
      medium: ['desconfort√°vel', 'ruim', 'incomoda', 'atrapalha'],
      low: ['leve', 'suport√°vel', 'toler√°vel', 'melhor']
    };

    const normalizedText = text.toLowerCase();
    
    let urgencyScore = 0;
    
    urgencyKeywords.critical.forEach(keyword => {
      if (normalizedText.includes(keyword)) urgencyScore += 3;
    });
    
    urgencyKeywords.high.forEach(keyword => {
      if (normalizedText.includes(keyword)) urgencyScore += 2;
    });
    
    urgencyKeywords.medium.forEach(keyword => {
      if (normalizedText.includes(keyword)) urgencyScore += 1;
    });
    
    urgencyKeywords.low.forEach(keyword => {
      if (normalizedText.includes(keyword)) urgencyScore -= 1;
    });

    // Normalizar para escala 0-10
    return Math.max(0, Math.min(10, urgencyScore));
  }

  /**
   * Avalia relev√¢ncia cl√≠nica do texto
   */
  assessClinicalRelevance(text: string): number {
    const clinicalKeywords = {
      high: ['dor', 'sintoma', 'medicamento', 'm√©dico', 'hospital', 'tratamento', 'crise'],
      medium: ['desconforto', 'mal-estar', 'cansa√ßo', 'stress', 'ansiedade'],
      low: ['normal', 'bem', 'rotina', 'trabalho']
    };

    const normalizedText = text.toLowerCase();
    let relevanceScore = 0;
    
    clinicalKeywords.high.forEach(keyword => {
      if (normalizedText.includes(keyword)) relevanceScore += 2;
    });
    
    clinicalKeywords.medium.forEach(keyword => {
      if (normalizedText.includes(keyword)) relevanceScore += 1;
    });
    
    clinicalKeywords.low.forEach(keyword => {
      if (normalizedText.includes(keyword)) relevanceScore -= 0.5;
    });

    // Normalizar para escala 0-10
    return Math.max(0, Math.min(10, relevanceScore));
  }

  /**
   * Extrai frases-chave do texto (implementa√ß√£o simples)
   */
  private extractKeyPhrases(text: string): string[] {
    // Implementa√ß√£o b√°sica - pode ser melhorada com NLP mais avan√ßado
    const sentences = text.split(/[.!?]+/).filter(s => s.trim().length > 10);
    const keywords = text.toLowerCase().match(/\b\w{4,}\b/g) || [];
    
    // Retornar frases mais relevantes baseadas em palavras-chave m√©dicas
    const medicalKeywords = ['dor', 'sintoma', 'medicamento', 'sono', 'humor', 'crise'];
    const relevantSentences = sentences.filter(sentence => 
      medicalKeywords.some(keyword => sentence.toLowerCase().includes(keyword))
    );

    return relevantSentences.slice(0, 3).map(s => s.trim());
  }

  /**
   * Processamento em paralelo de m√∫ltiplos textos (NOVO - BATCH PROCESSING)
   */
  async analyzeBatch(texts: string[]): Promise<NLPAnalysisResult[]> {
    if (texts.length === 0) return [];
    
    nlpLog(`üöÄ Processando ${texts.length} textos em batches...`);
    
    // Processar em batches de 5 textos para otimiza√ß√£o
    const BATCH_SIZE = 5;
    const batches: string[][] = [];
    
    for (let i = 0; i < texts.length; i += BATCH_SIZE) {
      batches.push(texts.slice(i, i + BATCH_SIZE));
    }
    
    // Processar batches em paralelo
    const batchPromises = batches.map(batch => 
      Promise.all(batch.map(text => this.analyzeText(text)))
    );
    
    const startTime = Date.now();
    const results = await Promise.all(batchPromises);
    const endTime = Date.now();
    
    const flatResults = results.flat();
    nlpLog(`‚ö° PERFORMANCE: Lote de ${texts.length} textos processado em ${endTime - startTime}ms (${Math.round((endTime - startTime) / texts.length)}ms/texto)`);
    
    return flatResults;
  }

  /**
   * Garantir que modelo de sumariza√ß√£o esteja carregado sob demanda
   */
  private async ensureSummaryModel(): Promise<void> {
    if (!this.summaryPipeline) {
      await this.initializeSummaryModel();
    }
  }

  /**
   * Garantir que modelo de classifica√ß√£o esteja carregado sob demanda
   */
  private async ensureClassificationModel(): Promise<void> {
    if (!this.classificationPipeline) {
      await this.initializeClassificationModel();
    }
  }

  /**
   * An√°lise completa de um texto
   */
  async analyzeText(text: string): Promise<NLPAnalysisResult> {
    if (!text || text.trim().length < 3) {
      throw new Error('Texto muito curto para an√°lise');
    }

    console.log('üß† Iniciando an√°lise NLP do texto...');

    try {
      // Executar an√°lises sequencialmente para reduzir carga
      console.log('üîç Analisando sentimento...');
      const sentiment = await this.analyzeSentiment(text);
      
      console.log('üè• Extraindo entidades m√©dicas...');
      const entities = await this.extractMedicalEntities(text);

      // An√°lises s√≠ncronas (baseadas em regras)
      console.log('‚ö° Calculando urg√™ncia e relev√¢ncia...');
      const urgencyLevel = this.detectUrgencyLevel(text);
      const clinicalRelevance = this.assessClinicalRelevance(text);

      // Gerar resumo se o texto for longo
      let summary: TextSummary | undefined;
      if (text.length > 100) {
        console.log('üìù Gerando resumo...');
        summary = await this.summarizeText(text);
      }

      // Mapear estado emocional baseado no sentimento
      const emotions: EmotionalState[] = [{
        primary: sentiment.label === 'POSITIVE' ? 'calmo' : 
                sentiment.label === 'NEGATIVE' ? 'preocupado' : 'neutro',
        intensity: sentiment.score * 10,
        confidence: sentiment.score
      }];

      const result: NLPAnalysisResult = {
        sentiment,
        summary,
        emotions,
        entities,
        urgencyLevel,
        clinicalRelevance
      };

      console.log('‚úÖ An√°lise NLP conclu√≠da:', {
        sentiment: sentiment.label,
        entitiesFound: entities.length,
        urgency: urgencyLevel,
        clinical: clinicalRelevance
      });
      return result;

    } catch (error) {
      console.error('‚ùå Erro na an√°lise NLP:', error);
      console.error('üìù Stack trace:', error instanceof Error ? error.stack : 'N/A');
      
      // Retornar resultado b√°sico em caso de erro total
      return {
        sentiment: { label: 'NEUTRAL', score: 0.5, confidence: 'LOW' },
        emotions: [{ primary: 'neutro', intensity: 5, confidence: 0.5 }],
        entities: [],
        urgencyLevel: 5,
        clinicalRelevance: 5
      };
    }
  }

  /**
   * Verifica se os modelos est√£o carregados
   */
  isReady(): boolean {
    return this.initialized && !this.isLoading;
  }

  /**
   * Retorna status detalhado dos modelos com informa√ß√µes de ambiente
   */
  getModelStatus(): { 
    sentiment: boolean; 
    summary: boolean; 
    classification: boolean; 
    fallbackMode: boolean;
    remoteSource: string;
    environment: string;
    configuration: EnvironmentConfig;
  } {
    return {
      sentiment: !!this.sentimentPipeline,
      summary: !!this.summaryPipeline,
      classification: !!this.classificationPipeline,
      fallbackMode: !this.initialized,
      remoteSource: 'Hugging Face Hub',
      environment: this.environmentConfig.name,
      configuration: this.environmentConfig
    };
  }
  
  /**
   * Verifica conectividade com Hugging Face Hub
   */
  private async checkRemoteConnectivity(): Promise<{ source: string; available: boolean; responseTime: number }> {
    const startTime = Date.now();
    try {
      // Teste simples de conectividade com HF Hub
      const testUrl = 'https://huggingface.co/api/models/Xenova/distilbert-base-uncased-finetuned-sst-2-english';
      const response = await fetch(testUrl, { 
        method: 'HEAD', 
        signal: AbortSignal.timeout(5000)
      });
      
      return {
        source: 'Hugging Face Hub',
        available: response.ok,
        responseTime: Date.now() - startTime
      };
    } catch (error) {
      return {
        source: 'Hugging Face Hub',
        available: false,
        responseTime: Date.now() - startTime
      };
    }
  }
  
  /**
   * Diagn√≥stico completo do sistema NLP
   */
  async getDiagnosticInfo(): Promise<{
    status: string;
    models: { sentiment: boolean; summary: boolean; classification: boolean };
    remote: { source: string; connectivity: boolean; responseTime: number };
    environment: { type: string; hostname: string; config: EnvironmentConfig };
    performance: { initTime: number | null; lastError: string | null };
    recommendations: string[];
  }> {
    const modelStatus = this.getModelStatus();
    const connectivity = await this.checkRemoteConnectivity();
    const recommendations: string[] = [];
    
    // Gerar recomenda√ß√µes baseadas no status
    if (modelStatus.fallbackMode) {
      recommendations.push('Modelos IA indispon√≠veis - usando an√°lise baseada em regras');
    }
    
    if (!connectivity.available) {
      recommendations.push('Verificar conectividade com Hugging Face Hub');
      recommendations.push('Tentar recarregar a p√°gina');
    }
    
    if (modelStatus.environment === 'Replit') {
      recommendations.push('Para produ√ß√£o, considere deploy no GitHub Pages para melhor performance');
    }
    
    if (modelStatus.environment === 'GitHub Pages' && !connectivity.available) {
      recommendations.push('Verificar CORS e conectividade externa');
    }
    
    return {
      status: this.isReady() ? 'Pronto' : this.isLoading ? 'Carregando' : 'Fallback',
      models: {
        sentiment: modelStatus.sentiment,
        summary: modelStatus.summary,
        classification: modelStatus.classification
      },
      remote: {
        source: connectivity.source,
        connectivity: connectivity.available,
        responseTime: connectivity.responseTime
      },
      environment: {
        type: modelStatus.environment,
        hostname: typeof window !== 'undefined' ? window.location.hostname : 'N/A',
        config: this.environmentConfig
      },
      performance: {
        initTime: null,
        lastError: null
      },
      recommendations
    };
  }

  /**
   * For√ßa reinicializa√ß√£o com limpeza de cache
   */
  async reinitializeWithCacheClear(): Promise<boolean> {
    console.log('üîÑ Reinicializando com limpeza de cache...');
    
    // Limpar modelos atuais
    this.dispose();
    
    // Limpar cache do browser se poss√≠vel
    try {
      if (typeof window !== 'undefined' && 'caches' in window) {
        const cacheNames = await caches.keys();
        await Promise.all(cacheNames.map(name => caches.delete(name)));
        console.log('üóëÔ∏è Cache do browser limpo');
      }
    } catch (error) {
      console.warn('‚ö†Ô∏è N√£o foi poss√≠vel limpar cache do browser');
    }
    
    // Reconfigurar ambiente
    this.configureEnvironment();
    
    // Tentar reinicializar
    try {
      await this.initialize();
      return this.isReady();
    } catch (error) {
      console.error('‚ùå Falha ao reinicializar:', error);
      return false;
    }
  }
  
  /**
   * Testa conectividade com Hugging Face Hub
   */
  async testRemoteConnectivity(): Promise<{ source: string; available: boolean; responseTime: number; details: string }> {
    console.log('üìã Testando conectividade com Hugging Face Hub...');
    
    const result = await this.checkRemoteConnectivity();
    
    const details = result.available 
      ? `Conectividade OK (${result.responseTime}ms)`
      : `Falha na conectividade (${result.responseTime}ms)`;
    
    console.log('üìã Resultado do teste:', { ...result, details });
    
    return {
      ...result,
      details
    };
  }
  
  /**
   * Libera recursos dos modelos (para economia de mem√≥ria)
   */
  /**
   * üöÄ OTIMIZA√á√ÉO: Recupera modelo do cache local
   */
  private getCachedModel(modelType: string): { model: any; timestamp: number; version: string } | null {
    try {
      const cacheKey = `nlp_model_${modelType}`;
      const cachedData = localStorage.getItem(cacheKey);
      
      if (!cachedData) return null;
      
      const parsed = JSON.parse(cachedData);
      const hoursSinceCache = (Date.now() - parsed.timestamp) / (1000 * 60 * 60);
      
      // Verificar expira√ß√£o e vers√£o
      if (hoursSinceCache > NLPAnalysisService.CACHE_EXPIRY_HOURS || 
          parsed.version !== NLPAnalysisService.CACHE_VERSION) {
        localStorage.removeItem(cacheKey);
        return null;
      }
      
      nlpLog(`‚ö° Cache hit: ${modelType} (${hoursSinceCache.toFixed(1)}h atr√°s)`);
      return parsed;
      
    } catch (error) {
      nlpLog(`‚ùå Erro ao recuperar cache: ${error}`);
      return null;
    }
  }

  /**
   * üöÄ OTIMIZA√á√ÉO: Salva modelo no cache local
   */
  private setCachedModel(modelType: string, model: any): void {
    try {
      const cacheKey = `nlp_model_${modelType}`;
      const cacheData = {
        model,
        timestamp: Date.now(),
        version: NLPAnalysisService.CACHE_VERSION
      };
      
      localStorage.setItem(cacheKey, JSON.stringify(cacheData));
      nlpLog(`‚ö° Modelo ${modelType} salvo no cache`);
      
    } catch (error) {
      nlpLog(`‚ùå Erro ao salvar cache: ${error}`);
    }
  }

  dispose(): void {
    this.sentimentPipeline = null;
    this.summaryPipeline = null;
    this.classificationPipeline = null;
    this.initialized = false;
    this.isLoading = false;
    console.log('üóëÔ∏è Modelos NLP liberados da mem√≥ria');
  }
}

// Inst√¢ncia singleton para reutiliza√ß√£o
export const nlpService = new NLPAnalysisService();